import streamlit as st

from langchain.chat_models import ChatOllama
from langchain.schema import SystemMessage, HumanMessage
from langchain.memory import ConversationBufferMemory

# streaming callbacks
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler # terminale yazmak
from langchain.callbacks.base import BaseCallbackHandler # streamlit ile calismak icin ozel handler
from typing import Any

# streamlit icin ozel streaming callback tanimi
class StreamHandler(BaseCallbackHandler):
    def __init__(self, placeholder):
        self.placeholder = placeholder # streamlit icindeki mesaj kutumuz
        self.final_text = ""

    def on_llm_new_token(self, token: str, **kwargs: Any) -> None:
        self.final_text += token # tokenlari birlestir
        self.placeholder.markdown(self.final_text + " ") # canli olarak yaz

# baslik ve aciklamalar
st.set_page_config(page_title = "AkÄ±llÄ± Turist Rehberi (CanlÄ±)", page_icon = "ğŸŒ")
st.title("ğŸŒ AkÄ±llÄ± Turist Rehberi (Streaming Modu)")
st.markdown("TÃ¼rkiye'nin dÃ¶rt bir yanÄ±ndaki turistik yerler hakkÄ±nda bilgi almak iÃ§in sorular sorabilirsiniz.")

# session state (streamlit de kullanici gecmisini tutmak icin)
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory( return_messages=True) # mesaj gecmisi

# mesaj kutusu: kullanicidan gelen mesaj
user_input = st.chat_input("Bir ÅŸehir, mekan, yemek ya da aktivite sorabilirsiniz...")

# sohbet gecmisini arayuzde goster
# tum mesajlari sirasiyla gezip ekrana bastiralim
for msg in st.session_state.memory.chat_memory.messages:
    if isinstance(msg, HumanMessage):
        with st.chat_message("ğŸ§‘â€ğŸ’¼ KullanÄ±cÄ±"):
            st.markdown(msg.content)
    else: # ai ise 
        with st.chat_message("ğŸ§­ AkÄ±llÄ± Rehber"):
            st.markdown(msg.content)

if user_input:
    # yeni gelen kullanici mesajini ilk olarak memory e ekliyoruz
    st.session_state.memory.chat_memory.add_user_message(user_input)
    with st.chat_message("ğŸ§‘â€ğŸ’¼ KullanÄ±cÄ±"):
        st.markdown(user_input)

    with st.chat_message("ğŸ§­ AkÄ±llÄ± Rehber"):

        response_placeholder = st.empty() # streamlitte geciic mesaj kutusu
        stream_handler = StreamHandler(response_placeholder) 

        llm = ChatOllama(model = "llama3.2:3b", streaming = True, callbacks = [stream_handler])

        # tum konusmayi modele verecek sekilde mesajlari olusturalim: sistem mesaji + memory + human message
        messages = [
            SystemMessage(content = "Sen akÄ±llÄ± turizm ve turist rehberisin. "
                        "kullanÄ±cÄ±lara TÃ¼rkiye'de ki ÅŸehirler, tarihi yerler, yÃ¶resel yemekler, ulaÅŸÄ±m ve tatil Ã¶nerileri hakkÄ±nda gÃ¼zel bilgiler ver. ")                   
        ] + st.session_state.memory.load_memory_variables({})["history"] + [HumanMessage(content = user_input)]

        # modelden yanit al
        response = llm(messages)

        # yaniti hafizaya kaydet
        st.session_state.memory.chat_memory.add_ai_message(response.content)